{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rk/1txw87pj7sgdsrd0ny5897580000gn/T/ipykernel_28419/3571106454.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'model_evaluations.xlsx',\n",
       " 'best_model.pkl',\n",
       " 'model_desarrollo.ipynb',\n",
       " 'datos_limpios.csv',\n",
       " 'limpieza_y_alistamiento_revisado.ipynb',\n",
       " 'data.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>actual_productivity</th>\n",
       "      <th>dia_del_a√±o</th>\n",
       "      <th>no_of_workers_redondeado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>2015-02-22</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>30.10</td>\n",
       "      <td>5700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307501</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.70</td>\n",
       "      <td>14.89</td>\n",
       "      <td>10260</td>\n",
       "      <td>50</td>\n",
       "      <td>0.700170</td>\n",
       "      <td>20</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>8220</td>\n",
       "      <td>75</td>\n",
       "      <td>0.850522</td>\n",
       "      <td>12</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2015-02-16</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>30.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800980</td>\n",
       "      <td>47</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>19.68</td>\n",
       "      <td>5760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.249417</td>\n",
       "      <td>50</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>20.40</td>\n",
       "      <td>10440</td>\n",
       "      <td>40</td>\n",
       "      <td>0.700251</td>\n",
       "      <td>22</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>2015-01-21</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>22.94</td>\n",
       "      <td>10260</td>\n",
       "      <td>34</td>\n",
       "      <td>0.700030</td>\n",
       "      <td>21</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951420</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>5</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.60</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592083</td>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.65</td>\n",
       "      <td>22.53</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581131</td>\n",
       "      <td>56</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971867</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>2015-02-04</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4</td>\n",
       "      <td>0.35</td>\n",
       "      <td>30.10</td>\n",
       "      <td>6060</td>\n",
       "      <td>23</td>\n",
       "      <td>0.350706</td>\n",
       "      <td>35</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2015-02-19</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>30.10</td>\n",
       "      <td>6960</td>\n",
       "      <td>50</td>\n",
       "      <td>0.700603</td>\n",
       "      <td>50</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2015-01-04</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667604</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>10</td>\n",
       "      <td>0.70</td>\n",
       "      <td>21.82</td>\n",
       "      <td>6000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>67</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>15.26</td>\n",
       "      <td>6120</td>\n",
       "      <td>23</td>\n",
       "      <td>0.350218</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2015-02-02</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.70</td>\n",
       "      <td>18.79</td>\n",
       "      <td>3960</td>\n",
       "      <td>30</td>\n",
       "      <td>0.700355</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646307</td>\n",
       "      <td>26</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>22.52</td>\n",
       "      <td>6840</td>\n",
       "      <td>113</td>\n",
       "      <td>1.000230</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779792</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2015-01-26</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1800</td>\n",
       "      <td>0</td>\n",
       "      <td>1.059621</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>2015-01-12</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.246250</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>2015-02-10</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1080</td>\n",
       "      <td>0</td>\n",
       "      <td>1.004889</td>\n",
       "      <td>41</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>30.40</td>\n",
       "      <td>3840</td>\n",
       "      <td>34</td>\n",
       "      <td>0.622828</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2015-01-11</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858144</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>2015-03-09</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>15.26</td>\n",
       "      <td>4080</td>\n",
       "      <td>63</td>\n",
       "      <td>0.800402</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Monday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>2400</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939514</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>10620</td>\n",
       "      <td>75</td>\n",
       "      <td>0.851174</td>\n",
       "      <td>10</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>42.97</td>\n",
       "      <td>10260</td>\n",
       "      <td>40</td>\n",
       "      <td>0.591142</td>\n",
       "      <td>25</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.858144</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  department        day  team  targeted_productivity    smv  \\\n",
       "882   2015-02-22      sweing     Sunday     5                   0.80  30.10   \n",
       "346   2015-01-20      sweing    Tuesday    11                   0.70  14.89   \n",
       "198   2015-01-12      sweing     Monday     1                   0.80  26.16   \n",
       "790   2015-02-16      sweing     Monday     5                   0.80  30.10   \n",
       "863   2015-02-19      sweing   Thursday    10                   0.70  19.68   \n",
       "380   2015-01-22      sweing   Thursday     5                   0.70  20.40   \n",
       "364   2015-01-21      sweing  Wednesday     1                   0.65  22.94   \n",
       "104   2015-01-07  finishing   Wednesday     1                   0.80   3.94   \n",
       "1063  2015-03-04   finishing  Wednesday     5                   0.70   4.60   \n",
       "939   2015-02-25      sweing  Wednesday     1                   0.65  22.53   \n",
       "523   2015-01-31  finishing    Saturday    10                   0.80   3.94   \n",
       "617   2015-02-04      sweing  Wednesday     4                   0.35  30.10   \n",
       "853   2015-02-19      sweing   Thursday     3                   0.70  30.10   \n",
       "58    2015-01-04  finishing      Sunday     7                   0.80   2.90   \n",
       "1120  2015-03-08      sweing     Sunday    10                   0.70  21.82   \n",
       "336   2015-01-19      sweing     Monday    12                   0.35  15.26   \n",
       "573   2015-02-02      sweing     Monday     6                   0.70  18.79   \n",
       "453   2015-01-26  finishing      Monday     7                   0.65   3.94   \n",
       "498   2015-01-29      sweing   Thursday     2                   0.80  22.52   \n",
       "141   2015-01-08  finishing    Thursday    10                   0.75   3.94   \n",
       "437   2015-01-26  finishing      Monday     3                   0.75   3.94   \n",
       "215   2015-01-12  finishing      Monday    10                   0.80   3.94   \n",
       "692   2015-02-10   finishing    Tuesday    12                   0.80   4.08   \n",
       "473   2015-01-27      sweing    Tuesday     6                   0.80  30.40   \n",
       "174   2015-01-11  finishing      Sunday     9                   0.80   3.94   \n",
       "1135  2015-03-09      sweing     Monday    12                   0.80  15.26   \n",
       "62    2015-01-05  finishing      Monday    11                   0.80   3.94   \n",
       "152   2015-01-10      sweing   Saturday     9                   0.80  26.16   \n",
       "434   2015-01-25      sweing     Sunday    11                   0.75  42.97   \n",
       "151   2015-01-10  finishing    Saturday     9                   0.80   3.94   \n",
       "\n",
       "      over_time  incentive  actual_productivity  dia_del_a√±o  \\\n",
       "882        5700          0             0.307501           53   \n",
       "346       10260         50             0.700170           20   \n",
       "198        8220         75             0.850522           12   \n",
       "790           0          0             0.800980           47   \n",
       "863        5760          0             0.249417           50   \n",
       "380       10440         40             0.700251           22   \n",
       "364       10260         34             0.700030           21   \n",
       "104        1440          0             0.951420            7   \n",
       "1063        960          0             0.592083           63   \n",
       "939        5040          0             0.581131           56   \n",
       "523        1200          0             0.971867           31   \n",
       "617        6060         23             0.350706           35   \n",
       "853        6960         50             0.700603           50   \n",
       "58          960          0             0.667604            4   \n",
       "1120       6000         30             0.700422           67   \n",
       "336        6120         23             0.350218           19   \n",
       "573        3960         30             0.700355           33   \n",
       "453        1440          0             0.646307           26   \n",
       "498        6840        113             1.000230           29   \n",
       "141        1440          0             0.779792            8   \n",
       "437        1800          0             1.059621           26   \n",
       "215        1440          0             0.246250           12   \n",
       "692        1080          0             1.004889           41   \n",
       "473        3840         34             0.622828           27   \n",
       "174        1440          0             0.858144           11   \n",
       "1135       4080         63             0.800402           68   \n",
       "62         2400          0             0.939514            5   \n",
       "152       10620         75             0.851174           10   \n",
       "434       10260         40             0.591142           25   \n",
       "151        1440          0             0.858144           10   \n",
       "\n",
       "      no_of_workers_redondeado  \n",
       "882                         60  \n",
       "346                         57  \n",
       "198                         59  \n",
       "790                         59  \n",
       "863                         48  \n",
       "380                         58  \n",
       "364                         57  \n",
       "104                          8  \n",
       "1063                         8  \n",
       "939                         42  \n",
       "523                         10  \n",
       "617                         55  \n",
       "853                         58  \n",
       "58                           8  \n",
       "1120                        50  \n",
       "336                         34  \n",
       "573                         33  \n",
       "453                          8  \n",
       "498                         57  \n",
       "141                          8  \n",
       "437                         10  \n",
       "215                          8  \n",
       "692                          9  \n",
       "473                         32  \n",
       "174                          8  \n",
       "1135                        34  \n",
       "62                          10  \n",
       "152                         59  \n",
       "434                         57  \n",
       "151                          8  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('datos_limpios.csv')\n",
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   date                      1197 non-null   object \n",
      " 1   department                1197 non-null   object \n",
      " 2   day                       1197 non-null   object \n",
      " 3   team                      1197 non-null   int64  \n",
      " 4   targeted_productivity     1197 non-null   float64\n",
      " 5   smv                       1197 non-null   float64\n",
      " 6   over_time                 1197 non-null   int64  \n",
      " 7   incentive                 1197 non-null   int64  \n",
      " 8   actual_productivity       1197 non-null   float64\n",
      " 9   dia_del_a√±o               1197 non-null   int64  \n",
      " 10  no_of_workers_redondeado  1197 non-null   int64  \n",
      "dtypes: float64(3), int64(5), object(3)\n",
      "memory usage: 103.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 1. explicativo\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "df_sample=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels) (1.26.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels) (1.12.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.4)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                    <td>    0.7488</td> <td>    0.009</td> <td>   80.136</td> <td> 0.000</td> <td>    0.730</td> <td>    0.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>incentive</th>                <td> 8.672e-05</td> <td> 3.14e-05</td> <td>    2.761</td> <td> 0.006</td> <td> 2.51e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>no_of_workers_redondeado</th> <td>   -0.0005</td> <td>    0.000</td> <td>   -2.173</td> <td> 0.030</td> <td>   -0.001</td> <td>-4.79e-05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                       &       0.7488  &        0.009     &    80.136  &         0.000        &        0.730    &        0.767     \\\\\n",
       "\\textbf{incentive}                   &    8.672e-05  &     3.14e-05     &     2.761  &         0.006        &     2.51e-05    &        0.000     \\\\\n",
       "\\textbf{no\\_of\\_workers\\_redondeado} &      -0.0005  &        0.000     &    -2.173  &         0.030        &       -0.001    &    -4.79e-05     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Preparing the data for multivariate regression\n",
    "X = df_sample[['incentive', 'no_of_workers_redondeado']]\n",
    "y = df_sample['actual_productivity']\n",
    "X = sm.add_constant(X)  # adding a constant\n",
    "\n",
    "# Fitting the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Getting the summary of the model\n",
    "model_summary = model.summary()\n",
    "model_summary\n",
    "#\n",
    "model_summary.tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'department', 'day', 'team', 'targeted_productivity', 'smv',\n",
       "       'over_time', 'incentive', 'actual_productivity', 'dia_del_a√±o',\n",
       "       'no_of_workers_redondeado'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team\n",
       "8     109\n",
       "2     109\n",
       "1     105\n",
       "4     105\n",
       "9     104\n",
       "10    100\n",
       "12     99\n",
       "7      96\n",
       "3      95\n",
       "6      94\n",
       "5      93\n",
       "11     88\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample[\"department\"]=[_.strip() for _ in  df_sample[\"department\"]]\n",
    "df_sample[\"department\"].value_counts()\n",
    "#\n",
    "df_sample[\"day\"].value_counts()\n",
    "#\n",
    "df_sample[\"team\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>actual_productivity</th>\n",
       "      <th>dia_del_a√±o</th>\n",
       "      <th>no_of_workers_redondeado</th>\n",
       "      <th>department_sweing</th>\n",
       "      <th>day_Saturday</th>\n",
       "      <th>...</th>\n",
       "      <th>team_3</th>\n",
       "      <th>team_4</th>\n",
       "      <th>team_5</th>\n",
       "      <th>team_6</th>\n",
       "      <th>team_7</th>\n",
       "      <th>team_8</th>\n",
       "      <th>team_9</th>\n",
       "      <th>team_10</th>\n",
       "      <th>team_11</th>\n",
       "      <th>team_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>2015-02-11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>22.52</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>1.000066</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>2015-02-14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.796208</td>\n",
       "      <td>45</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2760</td>\n",
       "      <td>0</td>\n",
       "      <td>0.930340</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>24.26</td>\n",
       "      <td>6960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.522845</td>\n",
       "      <td>36</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>30.10</td>\n",
       "      <td>3360</td>\n",
       "      <td>50</td>\n",
       "      <td>0.800511</td>\n",
       "      <td>67</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>2015-01-19</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.30</td>\n",
       "      <td>5040</td>\n",
       "      <td>0</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>0.80</td>\n",
       "      <td>22.52</td>\n",
       "      <td>6840</td>\n",
       "      <td>113</td>\n",
       "      <td>1.000230</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>2015-02-08</td>\n",
       "      <td>0.75</td>\n",
       "      <td>10.05</td>\n",
       "      <td>3240</td>\n",
       "      <td>45</td>\n",
       "      <td>0.750028</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>15.26</td>\n",
       "      <td>4080</td>\n",
       "      <td>63</td>\n",
       "      <td>0.800402</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>2015-03-08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1080</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945556</td>\n",
       "      <td>67</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2015-01-29</td>\n",
       "      <td>0.70</td>\n",
       "      <td>29.12</td>\n",
       "      <td>6960</td>\n",
       "      <td>53</td>\n",
       "      <td>0.850170</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.80</td>\n",
       "      <td>28.08</td>\n",
       "      <td>10350</td>\n",
       "      <td>50</td>\n",
       "      <td>0.800594</td>\n",
       "      <td>6</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970076</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>2015-03-05</td>\n",
       "      <td>0.35</td>\n",
       "      <td>22.53</td>\n",
       "      <td>2640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263694</td>\n",
       "      <td>64</td>\n",
       "      <td>39</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.952020</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>2015-03-07</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.590741</td>\n",
       "      <td>66</td>\n",
       "      <td>15</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2015-01-27</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.94</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.845458</td>\n",
       "      <td>27</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>0.75</td>\n",
       "      <td>19.31</td>\n",
       "      <td>9900</td>\n",
       "      <td>45</td>\n",
       "      <td>0.750058</td>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>15.26</td>\n",
       "      <td>4200</td>\n",
       "      <td>45</td>\n",
       "      <td>0.750647</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>2015-02-09</td>\n",
       "      <td>0.80</td>\n",
       "      <td>29.12</td>\n",
       "      <td>6960</td>\n",
       "      <td>50</td>\n",
       "      <td>0.799963</td>\n",
       "      <td>40</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.90</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>30.10</td>\n",
       "      <td>1200</td>\n",
       "      <td>49</td>\n",
       "      <td>0.598792</td>\n",
       "      <td>56</td>\n",
       "      <td>59</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>0.75</td>\n",
       "      <td>19.87</td>\n",
       "      <td>6600</td>\n",
       "      <td>45</td>\n",
       "      <td>0.750243</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.15</td>\n",
       "      <td>3060</td>\n",
       "      <td>0</td>\n",
       "      <td>0.973797</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>10620</td>\n",
       "      <td>75</td>\n",
       "      <td>0.850502</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>2015-02-07</td>\n",
       "      <td>0.60</td>\n",
       "      <td>30.10</td>\n",
       "      <td>6780</td>\n",
       "      <td>30</td>\n",
       "      <td>0.600224</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>2015-03-02</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.60</td>\n",
       "      <td>3360</td>\n",
       "      <td>0</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>2015-03-04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.61</td>\n",
       "      <td>15120</td>\n",
       "      <td>63</td>\n",
       "      <td>0.800107</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  targeted_productivity    smv  over_time  incentive  \\\n",
       "714   2015-02-11                   0.80  22.52          0        113   \n",
       "755   2015-02-14                   0.80   3.94       1440          0   \n",
       "149   2015-01-10                   0.75   4.15       2760          0   \n",
       "633   2015-02-05                   0.07  24.26       6960          0   \n",
       "1115  2015-03-08                   0.80  30.10       3360         50   \n",
       "318   2015-01-19                   0.70   4.30       5040          0   \n",
       "498   2015-01-29                   0.80  22.52       6840        113   \n",
       "667   2015-02-08                   0.75  10.05       3240         45   \n",
       "1116  2015-03-08                   0.80  15.26       4080         63   \n",
       "1107  2015-03-08                   0.80   4.60       1080          0   \n",
       "509   2015-01-29                   0.70  29.12       6960         53   \n",
       "93    2015-01-06                   0.80  28.08      10350         50   \n",
       "418   2015-01-25                   0.70   3.94       1440          0   \n",
       "1086  2015-03-05                   0.35  22.53       2640          0   \n",
       "421   2015-01-25                   0.75   4.30       2160          0   \n",
       "1102  2015-03-07                   0.80   4.60       3600          0   \n",
       "464   2015-01-27                   0.65   3.94        960          0   \n",
       "100   2015-01-06                   0.75  19.31       9900         45   \n",
       "536   2015-01-31                   0.75  15.26       4200         45   \n",
       "682   2015-02-09                   0.80  29.12       6960         50   \n",
       "623   2015-02-05                   0.70   2.90        960          0   \n",
       "938   2015-02-25                   0.80  30.10       1200         49   \n",
       "34    2015-01-03                   0.75  19.87       6600         45   \n",
       "416   2015-01-25                   0.70   4.15       3060          0   \n",
       "222   2015-01-13                   0.80  26.16      10620         75   \n",
       "651   2015-02-07                   0.60  30.10       6780         30   \n",
       "12    2015-01-01                   0.80  11.41       3660         50   \n",
       "1014  2015-03-02                   0.75   4.60       3360          0   \n",
       "1047  2015-03-04                   0.80   4.60       1200          0   \n",
       "138   2015-01-08                   0.80  11.61      15120         63   \n",
       "\n",
       "      actual_productivity  dia_del_a√±o  no_of_workers_redondeado  \\\n",
       "714              1.000066           42                        57   \n",
       "755              0.796208           45                        12   \n",
       "149              0.930340           10                        12   \n",
       "633              0.522845           36                        58   \n",
       "1115             0.800511           67                        57   \n",
       "318              0.977273           19                        28   \n",
       "498              1.000230           29                        57   \n",
       "667              0.750028           39                        27   \n",
       "1116             0.800402           67                        34   \n",
       "1107             0.945556           67                         9   \n",
       "509              0.850170           29                        58   \n",
       "93               0.800594            6                        57   \n",
       "418              0.970076           25                         8   \n",
       "1086             0.263694           64                        39   \n",
       "421              0.952020           25                        12   \n",
       "1102             0.590741           66                        15   \n",
       "464              0.845458           27                         8   \n",
       "100              0.750058            6                        55   \n",
       "536              0.750647           31                        35   \n",
       "682              0.799963           40                        58   \n",
       "623              0.942500           36                         8   \n",
       "938              0.598792           56                        59   \n",
       "34               0.750243            3                        55   \n",
       "416              0.973797           25                        17   \n",
       "222              0.850502           13                        59   \n",
       "651              0.600224           38                        57   \n",
       "12               0.707046            1                        30   \n",
       "1014             0.773333           61                         8   \n",
       "1047             0.939167           63                        10   \n",
       "138              0.800107            8                        31   \n",
       "\n",
       "      department_sweing  day_Saturday  ...  team_3  team_4  team_5  team_6  \\\n",
       "714                True         False  ...   False   False   False   False   \n",
       "755               False          True  ...   False   False   False   False   \n",
       "149               False          True  ...    True   False   False   False   \n",
       "633                True         False  ...   False   False   False   False   \n",
       "1115               True         False  ...    True   False   False   False   \n",
       "318               False         False  ...   False    True   False   False   \n",
       "498                True         False  ...   False   False   False   False   \n",
       "667                True         False  ...   False   False   False   False   \n",
       "1116               True         False  ...   False   False   False   False   \n",
       "1107              False         False  ...   False   False   False   False   \n",
       "509                True         False  ...   False   False   False   False   \n",
       "93                 True         False  ...   False    True   False   False   \n",
       "418               False         False  ...   False   False   False   False   \n",
       "1086               True         False  ...   False   False   False    True   \n",
       "421               False         False  ...   False    True   False   False   \n",
       "1102              False          True  ...   False   False   False   False   \n",
       "464               False         False  ...   False   False   False   False   \n",
       "100                True         False  ...   False   False   False   False   \n",
       "536                True          True  ...   False   False   False   False   \n",
       "682                True         False  ...   False   False   False   False   \n",
       "623               False         False  ...   False   False   False    True   \n",
       "938                True         False  ...   False   False    True   False   \n",
       "34                 True          True  ...   False   False   False   False   \n",
       "416               False         False  ...   False   False    True   False   \n",
       "222                True         False  ...   False   False   False   False   \n",
       "651                True          True  ...   False    True   False   False   \n",
       "12                 True         False  ...   False   False    True   False   \n",
       "1014              False         False  ...   False   False   False   False   \n",
       "1047              False         False  ...    True   False   False   False   \n",
       "138                True         False  ...   False   False   False   False   \n",
       "\n",
       "      team_7  team_8  team_9  team_10  team_11  team_12  \n",
       "714    False   False   False    False    False    False  \n",
       "755    False   False   False    False    False    False  \n",
       "149    False   False   False    False    False    False  \n",
       "633     True   False   False    False    False    False  \n",
       "1115   False   False   False    False    False    False  \n",
       "318    False   False   False    False    False    False  \n",
       "498    False   False   False    False    False    False  \n",
       "667    False   False   False    False     True    False  \n",
       "1116   False   False   False    False    False     True  \n",
       "1107   False   False   False    False    False     True  \n",
       "509    False   False    True    False    False    False  \n",
       "93     False   False   False    False    False    False  \n",
       "418    False   False   False    False    False    False  \n",
       "1086   False   False   False    False    False    False  \n",
       "421    False   False   False    False    False    False  \n",
       "1102   False    True   False    False    False    False  \n",
       "464    False    True   False    False    False    False  \n",
       "100    False   False   False    False     True    False  \n",
       "536    False   False   False    False    False     True  \n",
       "682    False   False    True    False    False    False  \n",
       "623    False   False   False    False    False    False  \n",
       "938    False   False   False    False    False    False  \n",
       "34     False   False   False    False    False    False  \n",
       "416    False   False   False    False    False    False  \n",
       "222    False   False    True    False    False    False  \n",
       "651    False   False   False    False    False    False  \n",
       "12     False   False   False    False    False    False  \n",
       "1014   False    True   False    False    False    False  \n",
       "1047   False   False   False    False    False    False  \n",
       "138    False   False   False    False    False     True  \n",
       "\n",
       "[30 rows x 25 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df_sample is your DataFrame\n",
    "# Apply one-hot encoding to 'department' and 'day' with k-1 columns\n",
    "df_encoded = pd.get_dummies(df_sample, columns=['department', 'day', \"team\"], drop_first=True)\n",
    "\n",
    "# Display the first few rows of the new DataFrame\n",
    "df_encoded.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   targeted_productivity     1197 non-null   float64\n",
      " 1   smv                       1197 non-null   float64\n",
      " 2   over_time                 1197 non-null   int64  \n",
      " 3   incentive                 1197 non-null   int64  \n",
      " 4   actual_productivity       1197 non-null   float64\n",
      " 5   dia_del_a√±o               1197 non-null   int64  \n",
      " 6   no_of_workers_redondeado  1197 non-null   int64  \n",
      " 7   department_sweing         1197 non-null   bool   \n",
      " 8   day_Saturday              1197 non-null   bool   \n",
      " 9   day_Sunday                1197 non-null   bool   \n",
      " 10  day_Thursday              1197 non-null   bool   \n",
      " 11  day_Tuesday               1197 non-null   bool   \n",
      " 12  day_Wednesday             1197 non-null   bool   \n",
      " 13  team_2                    1197 non-null   bool   \n",
      " 14  team_3                    1197 non-null   bool   \n",
      " 15  team_4                    1197 non-null   bool   \n",
      " 16  team_5                    1197 non-null   bool   \n",
      " 17  team_6                    1197 non-null   bool   \n",
      " 18  team_7                    1197 non-null   bool   \n",
      " 19  team_8                    1197 non-null   bool   \n",
      " 20  team_9                    1197 non-null   bool   \n",
      " 21  team_10                   1197 non-null   bool   \n",
      " 22  team_11                   1197 non-null   bool   \n",
      " 23  team_12                   1197 non-null   bool   \n",
      "dtypes: bool(17), float64(3), int64(4)\n",
      "memory usage: 85.5 KB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_encoded.drop([\"date\"],axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['targeted_productivity',\n",
       " 'smv',\n",
       " 'over_time',\n",
       " 'incentive',\n",
       " 'dia_del_a√±o',\n",
       " 'no_of_workers_redondeado',\n",
       " 'department_sweing',\n",
       " 'day_Saturday',\n",
       " 'day_Sunday',\n",
       " 'day_Thursday',\n",
       " 'day_Tuesday',\n",
       " 'day_Wednesday',\n",
       " 'team_2',\n",
       " 'team_3',\n",
       " 'team_4',\n",
       " 'team_5',\n",
       " 'team_6',\n",
       " 'team_7',\n",
       " 'team_8',\n",
       " 'team_9',\n",
       " 'team_10',\n",
       " 'team_11',\n",
       " 'team_12']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indenpendent_vars=[_ for _ in df_encoded.columns if _!='actual_productivity' ]\n",
    "indenpendent_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------\n",
      "const                        0.3319      0.042      7.917      0.000       0.250       0.414\n",
      "targeted_productivity        0.6822      0.046     14.802      0.000       0.592       0.773\n",
      "smv                         -0.0072      0.001     -6.965      0.000      -0.009      -0.005\n",
      "over_time                -4.543e-06   2.06e-06     -2.203      0.028   -8.59e-06   -4.97e-07\n",
      "incentive                 6.787e-05   2.75e-05      2.471      0.014     1.4e-05       0.000\n",
      "dia_del_a√±o                 -0.0010      0.000     -4.328      0.000      -0.001      -0.001\n",
      "no_of_workers_redondeado     0.0051      0.001      5.804      0.000       0.003       0.007\n",
      "department_sweing           -0.0758      0.034     -2.224      0.026      -0.143      -0.009\n",
      "day_Saturday                 0.0179      0.015      1.174      0.241      -0.012       0.048\n",
      "day_Sunday                  -0.0028      0.015     -0.185      0.853      -0.032       0.027\n",
      "day_Thursday                -0.0046      0.015     -0.304      0.761      -0.034       0.025\n",
      "day_Tuesday                  0.0177      0.015      1.182      0.238      -0.012       0.047\n",
      "day_Wednesday                0.0035      0.015      0.232      0.816      -0.026       0.033\n",
      "team_2                      -0.0498      0.020     -2.454      0.014      -0.090      -0.010\n",
      "team_3                      -0.0130      0.021     -0.620      0.535      -0.054       0.028\n",
      "team_4                      -0.0301      0.021     -1.465      0.143      -0.070       0.010\n",
      "team_5                      -0.0656      0.021     -3.063      0.002      -0.108      -0.024\n",
      "team_6                      -0.0949      0.024     -4.016      0.000      -0.141      -0.049\n",
      "team_7                      -0.1208      0.021     -5.736      0.000      -0.162      -0.079\n",
      "team_8                      -0.1121      0.020     -5.491      0.000      -0.152      -0.072\n",
      "team_9                      -0.0945      0.021     -4.601      0.000      -0.135      -0.054\n",
      "team_10                     -0.0987      0.021     -4.750      0.000      -0.139      -0.058\n",
      "team_11                     -0.1475      0.022     -6.579      0.000      -0.192      -0.104\n",
      "team_12                     -0.0352      0.023     -1.502      0.133      -0.081       0.011\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Asegurarse de que los datos sean num√©ricos y no contengan valores faltantes\n",
    "df_encoded = df_encoded.astype(float).dropna()\n",
    "\n",
    "# Preparar los datos para la regresi√≥n multivariada\n",
    "X = df_encoded[indenpendent_vars]\n",
    "y = df_encoded['actual_productivity']\n",
    "X = sm.add_constant(X)  # a√±adir una constante\n",
    "\n",
    "# Ajustar el modelo\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener el resumen del modelo\n",
    "model_summary = model.summary()\n",
    "\n",
    "# Acceder a la Tabla 1 del resumen\n",
    "table1 = model_summary.tables[1]\n",
    "print(table1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (5.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>t</th>\n",
       "      <th>P&gt;|t|</th>\n",
       "      <th>[0.025</th>\n",
       "      <th>0.975]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>incentive</td>\n",
       "      <td>6.787e-05</td>\n",
       "      <td>2.75e-05</td>\n",
       "      <td>2.471</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.4e-05</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_of_workers_redondeado</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5.804</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                parameters       coef   std err      t  P>|t|   [0.025 0.975]\n",
       "5                 incentive  6.787e-05  2.75e-05  2.471  0.014  1.4e-05  0.000\n",
       "7  no_of_workers_redondeado     0.0051     0.001  5.804  0.000    0.003  0.007"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "#\n",
    "table_output=model_summary.tables[1]\n",
    "# Assuming 'table_output' is your SimpleTable object\n",
    "html_table = table_output.as_html()\n",
    "df_list = pd.read_html(StringIO(html_table))\n",
    "\n",
    "# Convert the list of DataFrames to a single DataFrame\n",
    "# (Assuming there's only one table in the list)\n",
    "table_output = df_list[0]\n",
    "table_output\n",
    "\n",
    "# Assuming table_output is your DataFrame\n",
    "# Set the first column as the index (variable names)\n",
    "table_output.columns=table_output.iloc[0]\n",
    "\n",
    "# Rename the first column to 'parameters'\n",
    "table_output.rename(columns={table_output.columns[0]: 'parameters'}, inplace=True)\n",
    "\n",
    "# Filter the DataFrame to include only the rows with 'incentive' or 'no_of_workers_redondeado' in 'parameters' column\n",
    "filtered_table = table_output[table_output['parameters'].isin([\"incentive\", \"no_of_workers_redondeado\"])]\n",
    "filtered_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# 2. predictivo\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_encoded[\"actual_productivity\"].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   targeted_productivity     1197 non-null   float64\n",
      " 1   smv                       1197 non-null   float64\n",
      " 2   over_time                 1197 non-null   float64\n",
      " 3   incentive                 1197 non-null   float64\n",
      " 4   actual_productivity       1197 non-null   float64\n",
      " 5   dia_del_a√±o               1197 non-null   float64\n",
      " 6   no_of_workers_redondeado  1197 non-null   float64\n",
      " 7   department_sweing         1197 non-null   float64\n",
      " 8   day_Saturday              1197 non-null   float64\n",
      " 9   day_Sunday                1197 non-null   float64\n",
      " 10  day_Thursday              1197 non-null   float64\n",
      " 11  day_Tuesday               1197 non-null   float64\n",
      " 12  day_Wednesday             1197 non-null   float64\n",
      " 13  team_2                    1197 non-null   float64\n",
      " 14  team_3                    1197 non-null   float64\n",
      " 15  team_4                    1197 non-null   float64\n",
      " 16  team_5                    1197 non-null   float64\n",
      " 17  team_6                    1197 non-null   float64\n",
      " 18  team_7                    1197 non-null   float64\n",
      " 19  team_8                    1197 non-null   float64\n",
      " 20  team_9                    1197 non-null   float64\n",
      " 21  team_10                   1197 non-null   float64\n",
      " 22  team_11                   1197 non-null   float64\n",
      " 23  team_12                   1197 non-null   float64\n",
      "dtypes: float64(24)\n",
      "memory usage: 224.6 KB\n"
     ]
    }
   ],
   "source": [
    "model_data=df_encoded.copy()\n",
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-10 19:56:48.834071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Assuming model_data is your DataFrame\n",
    "# Splitting the data into features (X) and target (y)\n",
    "X = model_data.drop('actual_productivity', axis=1)\n",
    "y = model_data['actual_productivity']\n",
    "\n",
    "# Splitting the dataset into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 3ms/step - loss: 0.3561\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.1580\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1068\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0863\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0730\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0620\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0546\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0492\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0443\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0404\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0376\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0350\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0327\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0307\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0291\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0268\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0257\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0246\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0241\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0220\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0215\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0211\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0206\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0188\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0170\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0150\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0145\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Out-of-Sample R¬≤: 0.04644021775520668\n"
     ]
    }
   ],
   "source": [
    "# Building the ANN model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Single hidden layer with 32 neurons\n",
    "    Dense(1,  activation='linear')  # Output layer for regression (linear activation)\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32)\n",
    "#\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Out-of-Sample R¬≤: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.7844\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.3101\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.1733\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1255\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1019\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0856\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0729\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0633\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0561\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0498\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0450\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0382\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0356\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0331\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0315\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0296\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0286\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0262\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0245\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0239\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0232\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0226\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0218\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0208\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0199\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0196\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0192\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0188\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0174\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0172\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0168\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0162\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0156\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0152\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Out-of-Sample R¬≤: 0.1682238156972119\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.2297\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0616\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0452\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0384\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0341\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0306\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0284\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0266\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0234\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0225\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0191\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0185\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0180\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0171\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0163\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0155\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0149\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0146\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0141\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0140\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0130\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0133\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0129\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0128\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0129\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0127\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0122\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0124\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0122\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0120\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0118\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0115\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Out-of-Sample R¬≤ for model2: -0.056408062355648214\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Building the ANN model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # Single hidden layer with 32 neurons\n",
    "    Dense(1,  activation='linear')  # Output layer for regression (linear activation)\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_scaled, y_train, epochs=50, batch_size=32)\n",
    "#\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Out-of-Sample R¬≤: {r2}\")\n",
    "\n",
    "\n",
    "# Building the ANN model with two hidden layers\n",
    "model2 = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),  # First hidden layer with 32 neurons\n",
    "    Dense(32, activation='relu'),  # Second hidden layer with 32 neurons\n",
    "    Dense(1,  activation='linear')  # Output layer for regression (linear activation)\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Training the model\n",
    "model2.fit(X_train_scaled, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred2 = model2.predict(X_test_scaled)\n",
    "r2_2 = r2_score(y_test, y_pred2)\n",
    "print(f\"Out-of-Sample R¬≤ for model2: {r2_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 2ms/step - loss: 1.6122\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.5906\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1664\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.1212\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0952\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.0796\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0687\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0606\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0545\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0497\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0458\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 0.0424\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0397\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0373\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0351\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0337\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0319\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0304\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 0.0294\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0282\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0273\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0264\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0255\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0248\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0242\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0235\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0228\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0224\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0219\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0213\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0209\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0205\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0200\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0197\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0193\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0190\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0187\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0184\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0176\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0175\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0173\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0167\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0164\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0161\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0159\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0158\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "Epoch 1/50\n",
      "30/30 [==============================] - 1s 2ms/step - loss: 0.2706\n",
      "Epoch 2/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0943\n",
      "Epoch 3/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0621\n",
      "Epoch 4/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0485\n",
      "Epoch 5/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0413\n",
      "Epoch 6/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0361\n",
      "Epoch 7/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0324\n",
      "Epoch 8/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0297\n",
      "Epoch 9/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0271\n",
      "Epoch 10/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0253\n",
      "Epoch 11/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0239\n",
      "Epoch 12/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0224\n",
      "Epoch 13/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0210\n",
      "Epoch 14/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0203\n",
      "Epoch 15/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0194\n",
      "Epoch 16/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0186\n",
      "Epoch 17/50\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 18/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 19/50\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 20/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 21/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0160\n",
      "Epoch 22/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0156\n",
      "Epoch 23/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0154\n",
      "Epoch 24/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0150\n",
      "Epoch 25/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0153\n",
      "Epoch 26/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0145\n",
      "Epoch 27/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0143\n",
      "Epoch 28/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0142\n",
      "Epoch 29/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0141\n",
      "Epoch 30/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 31/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0135\n",
      "Epoch 32/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0137\n",
      "Epoch 33/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0131\n",
      "Epoch 34/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 35/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0130\n",
      "Epoch 36/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0125\n",
      "Epoch 37/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0124\n",
      "Epoch 38/50\n",
      "30/30 [==============================] - 0s 3ms/step - loss: 0.0126\n",
      "Epoch 39/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0127\n",
      "Epoch 40/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0119\n",
      "Epoch 41/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0118\n",
      "Epoch 42/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0117\n",
      "Epoch 43/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 44/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0114\n",
      "Epoch 45/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0116\n",
      "Epoch 46/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 47/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0112\n",
      "Epoch 48/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0111\n",
      "Epoch 49/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0109\n",
      "Epoch 50/50\n",
      "30/30 [==============================] - 0s 2ms/step - loss: 0.0110\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def save_optimal_model(n_epochs, X_train_scaled, y_train, X_test_scaled, y_test):\n",
    "    # Define the first model\n",
    "    model1 = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model1.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=32)\n",
    "    y_pred1 = model1.predict(X_test_scaled)\n",
    "    r2_1 = r2_score(y_test, y_pred1)\n",
    "    gist_1 = \"1 Layer: 32 Neurons (ReLU)\"\n",
    "\n",
    "    # Define the second model\n",
    "    model2 = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model2.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=32)\n",
    "    y_pred2 = model2.predict(X_test_scaled)\n",
    "    r2_2 = r2_score(y_test, y_pred2)\n",
    "    gist_2 = \"2 Layers: 32 Neurons each (ReLU)\"\n",
    "\n",
    "    # Create DataFrame with evaluations\n",
    "    evaluations = pd.DataFrame({'Model': ['Model 1', 'Model 2'], \n",
    "                                'Out-of-Sample R¬≤': [r2_1, r2_2],\n",
    "                                'Model Gist': [gist_1, gist_2]})\n",
    "    # Export to Excel\n",
    "    evaluations.to_excel('model_evaluations.xlsx', index=False)\n",
    "\n",
    "    # Save the optimal model\n",
    "    best_model = model1 if r2_1 > r2_2 else model2\n",
    "    with open('best_model.pkl', 'wb') as file:\n",
    "        pickle.dump(best_model, file)\n",
    "\n",
    "    return evaluations\n",
    "\n",
    "\n",
    "# Example usage\n",
    "evaluations = save_optimal_model(50, X_train_scaled, y_train, X_test_scaled, y_test)\n",
    "# Note: Make sure X_train_scaled, y_train, X_test_scaled, y_test are defined"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
